{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "authorship_tag": "ABX9TyN8ziySXnLR97WLY9HSwC1z",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/DuanMingbai/PyTorch_Tutorials_cn/blob/main/Introduction%20to%20PyTorch/2_%E5%BC%A0%E9%87%8F.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#张量"
      ],
      "metadata": {
        "id": "Hm1LBAOwxYVg"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "张量（tensor）是一种很特殊的数据类型，它和数组、矩阵非常像，在使用PyTorch的时候，我们在一个模型中用tensor来为输入和输出编码，包括模型当中的参数\n",
        "\n",
        "tensor和Numpy's的ndarrays很像，除此之外，tensor可以运行在GPU或者其他硬件加速器上。事实上tensor和Numpy的array通常可以享用相同的底层内存，所以说不需要取复制数据（详情见[Bridge with NumPy](https://pytorch.org/tutorials/beginner/blitz/tensor_tutorial.html#bridge-to-np-label)）。如果你对ndarrays很熟悉的话，你使用tensorAPI将会如有神助，如果不熟悉，那咱们就开始吧！"
      ],
      "metadata": {
        "id": "2yi3viYpxbgQ"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RC66l3JPxRp_"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##初始化一个tensor"
      ],
      "metadata": {
        "id": "DHOHsTgoY3jz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor能够被各种方式初始化，让我们来看如下几个方式"
      ],
      "metadata": {
        "id": "k0gz4SwsZpC8"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "###直接干数据"
      ],
      "metadata": {
        "id": "OgTDTv8iaC1m"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data = [[1, 2],[3, 4]]\n",
        "x_data = torch.tensor(data)"
      ],
      "metadata": {
        "id": "oaQjN1mIY262"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###通过Numpy的array"
      ],
      "metadata": {
        "id": "3AIc0wl8aAk2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np_array = np.array(data)\n",
        "x_np = torch.from_numpy(np_array)"
      ],
      "metadata": {
        "id": "jDlEEcvuaLnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###通过其他的tensor"
      ],
      "metadata": {
        "id": "hKb2YQSLbPet"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "新tensor保留参数tensor的属性（维度，数据类型），除了完全覆盖"
      ],
      "metadata": {
        "id": "3G-bqHQra332"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x_ones = torch.ones_like(x_data) # retains the properties of x_data\n",
        "print(f\"Ones Tensor: \\n {x_ones} \\n\")\n",
        "\n",
        "x_rand = torch.rand_like(x_data, dtype=torch.float) # overrides the datatype of x_data\n",
        "print(f\"Random Tensor: \\n {x_rand} \\n\")"
      ],
      "metadata": {
        "id": "Cm-3WG5DbVZp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "###通过任意的常量"
      ],
      "metadata": {
        "id": "mbb-FsY7cAQR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "shape = (2,3,)\n",
        "rand_tensor = torch.rand(shape)\n",
        "ones_tensor = torch.ones(shape)\n",
        "zeros_tensor = torch.zeros(shape)\n",
        "\n",
        "print(f\"Random Tensor: \\n {rand_tensor} \\n\")\n",
        "print(f\"Ones Tensor: \\n {ones_tensor} \\n\")\n",
        "print(f\"Zeros Tensor: \\n {zeros_tensor}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZsUQTP4Ib_qx",
        "outputId": "4b9fb8f5-8790-4d55-9e8e-f5fede568302"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Tensor: \n",
            " tensor([[0.5954, 0.0105, 0.4852],\n",
            "        [0.6647, 0.5206, 0.2294]]) \n",
            "\n",
            "Ones Tensor: \n",
            " tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.]]) \n",
            "\n",
            "Zeros Tensor: \n",
            " tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tensor的属性"
      ],
      "metadata": {
        "id": "QDrd88OjeyGN"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tensor的属性描述了它的维度，数据类型和这个家伙存储在哪个设备上"
      ],
      "metadata": {
        "id": "paqp1TdEfZJY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor = torch.rand(3,4)\n",
        "\n",
        "print(f\"Shape of tensor: {tensor.shape}\")\n",
        "print(f\"Datatype of tensor: {tensor.dtype}\")\n",
        "print(f\"Device tensor is stored on: {tensor.device}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "35IhkqHtfOv8",
        "outputId": "302a6db1-1569-405b-8dc0-69d8eeb1897e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of tensor: torch.Size([3, 4])\n",
            "Datatype of tensor: torch.float32\n",
            "Device tensor is stored on: cpu\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Tensor的操作"
      ],
      "metadata": {
        "id": "5pwPf8Reh3iX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor的操作超过一百多种，包括算法，线性代数，矩阵操作（转置，切片，索引），采样，更多完整的描述点击[链接文字](https://pytorch.org/docs/stable/torch.html)。"
      ],
      "metadata": {
        "id": "aqOr8OMZh_Dq"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "这些操作都可以被运行在GPU上，如果你用Colab，通过修改运行时类型，来获取GPU。"
      ],
      "metadata": {
        "id": "WS63hVpw-V0-"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "tensor默认是被创建在CPU上的。我们可以准确度地移动tensor到GPU上用```.to```方法（当然了，必须保证你的GPU可用），但是要记住，在复制特别大的tensor到GPU的时候，会耗费大量的时间和存储。"
      ],
      "metadata": {
        "id": "fbYe_5P5-f01"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#我们将tensor移动到可用的GPU上\n",
        "if torch.cuda.is_available():\n",
        "  tensor = tensor.to(\"cuda\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SGIcZEOO-eHB",
        "outputId": "93cb136b-d88c-4c55-f221-7909f8011f24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "我们尝试一些列表当中的操作，如果你熟悉Numpy中的API，那么你会发现使用tensor就像过马路一样简单。"
      ],
      "metadata": {
        "id": "fOarzg52_wY4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**标准的类似Numpy索引和切片**"
      ],
      "metadata": {
        "id": "i7Pa9kGOBEmu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tensor=torch.ones(4, 4)\n",
        "print(tensor)\n",
        "print(f\"First row: {tensor[0]}\")\n",
        "print(f\"First column: {tensor[:,0]}\")\n",
        "tensor[:, 1]=0\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YmpTypJFBC2d",
        "outputId": "2e2427f5-d792-431f-bebe-a1d098c663bc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.],\n",
            "        [1., 1., 1., 1.]])\n",
            "First row: tensor([1., 1., 1., 1.])\n",
            "First column: tensor([1., 1., 1., 1.])\n",
            "tensor([[1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**组合tensor**，你可以使用```torch.cat```根据给定维度去连接一系列的tensor，另请参阅[torch.stack](https://pytorch.org/docs/stable/generated/torch.stack.html)"
      ],
      "metadata": {
        "id": "KdEV5YNxEuuh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t1 = torch.cat([tensor,tensor,tensor], dim=1)\n",
        "print(t1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rklARZdOGwM7",
        "outputId": "f9a29315-59e0-49e2-d32d-62899c86595e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.],\n",
            "        [1., 0., 1., 1., 1., 0., 1., 1., 1., 0., 1., 1.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**算法操作**"
      ],
      "metadata": {
        "id": "K_5ycTNaHuaa"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#下面的代码计算了连个tensor的乘法，y1,y2,y3会有相同的结果\n",
        "y1 = tensor @ tensor.T\n",
        "y2 = tensor.matmul(tensor.T)\n",
        "\n",
        "y3 = torch.rand_like(y1)\n",
        "torch.matmul(tensor, tensor.T, out=y3)\n",
        "\n",
        "\n",
        "#下面代码计算每一个元素的乘积，z1,z2,z3会有相同值\n",
        "z1 = tensor * tensor\n",
        "z1 = tensor.mul(tensor)\n",
        "\n",
        "z3=torch.rand_like(tensor)\n",
        "torch.mul(tensor, tensor,out=z3)\n",
        "#译者理解，这两个的区别应该是，第一个是标准的矩阵乘法（行x列然后相加），第二个是将简单的将每个元素乘起来"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRMzh-Y9HzMm",
        "outputId": "60d1862b-5737-41c5-aa9b-c632f77c9a1d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.],\n",
              "        [1., 0., 1., 1.]])"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**单元素tensor**如果你有一个单元素tensor，例如将tensor所有值聚合为一个值，你可以通过```item()```将这个tensor转换成Python的数值"
      ],
      "metadata": {
        "id": "M3ePhXE-PRzH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "agg = tensor.sum()\n",
        "print(agg)\n",
        "agg_item = agg.item()\n",
        "print(agg_item,type(agg_item))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPhz2IApYuuI",
        "outputId": "ef5f151e-e525-4955-9f70-96ed49e6cc46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(12.)\n",
            "12.0 <class 'float'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "**自动赋值操作**将结果存储在操作数中的操作被称作自动赋值操作。他们用```_```后缀表示，例如：```x.copy_(y)```，```x.t_()```，会更改```x```。"
      ],
      "metadata": {
        "id": "AjrDz2wkfI_2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"{tensor} \\n\")\n",
        "tensor.add_(5)\n",
        "print(tensor)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IMi7wt5Hioyp",
        "outputId": "3cb469cc-dc69-4d59-a06c-cb5ba1f988da"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.],\n",
            "        [6., 5., 6., 6.]]) \n",
            "\n",
            "tensor([[11., 10., 11., 11.],\n",
            "        [11., 10., 11., 11.],\n",
            "        [11., 10., 11., 11.],\n",
            "        [11., 10., 11., 11.]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note\n",
        "\n",
        "自动赋值操作节省了一些内存，但是在计算导数的时候会报错因为会立刻丢掉历史记录。所以，不推荐使用这个方法。"
      ],
      "metadata": {
        "id": "kfewIMF4lM_p"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##与Numpy桥接"
      ],
      "metadata": {
        "id": "shT6NOt6nuej"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "CPU 和 NumPy 数组上的张量可以共享它们的底层内存位置，改变一个也会改变另一个。"
      ],
      "metadata": {
        "id": "KI-Foi1XpsUi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t = torch.ones(5)\n",
        "print(f\"t: {t}\")\n",
        "n=t.numpy()\n",
        "print(f\"n: {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wjeXBMLBpV-O",
        "outputId": "905f8bb1-a8cc-4f0a-f5a1-3e7271c6dab7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([1., 1., 1., 1., 1.])\n",
            "n: [1. 1. 1. 1. 1.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Tensor to NumPy array"
      ],
      "metadata": {
        "id": "IS2wWKf3p5Eo"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "在tensor上做出改变的时候映射在Numpy array"
      ],
      "metadata": {
        "id": "Ms3eysCFqBNq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "t.add_(1)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n： {n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PALXQlyEp7v8",
        "outputId": "e22edcb5-8f2b-4b9b-bf92-2fd569d7baec"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([2., 2., 2., 2., 2.])\n",
            "n： [2. 2. 2. 2. 2.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "###Numpy array转换tensor"
      ],
      "metadata": {
        "id": "K4AMbG3-qe4_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "n=np.ones(5)\n",
        "t=torch.from_numpy(n)"
      ],
      "metadata": {
        "id": "DWz8_RGgqmiz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "在array上做出改变会映射到tensor中"
      ],
      "metadata": {
        "id": "yjR9BYBTq3Fw"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "np.add(n,1,out=n)\n",
        "print(f\"t: {t}\")\n",
        "print(f\"n:{n}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BeJamj9YrCOS",
        "outputId": "74c3956a-abc1-4aaf-914c-2d4d6c28e016"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "t: tensor([4., 4., 4., 4., 4.])\n",
            "n:[4. 4. 4. 4. 4.]\n"
          ]
        }
      ]
    }
  ]
}